{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'splinter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fb89eda2bd9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msplinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBrowser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minit_browser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'splinter'"
     ]
    }
   ],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)\n",
    "\n",
    "\n",
    "def scrape():\n",
    "    browser = init_browser()\n",
    "    marsdata = {}\n",
    "    # 1-NASA Mars News\n",
    "    url = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # Extract the lastest title and its article teaser on the NASA Mars News\n",
    "    news_title = soup.find('div', class_='content_title').text.strip()\n",
    "    news_p = soup.find('div',class_='article_teaser_body').text.strip()\n",
    "    linknews = \"https://mars.nasa.gov/\" + soup.find('div', class_='content_title')('a')[0][\"href\"]\n",
    "    marsdata[\"newstitle\"] =news_title\n",
    "    marsdata[\"newscontenteaser\"] = news_p\n",
    "    marsdata[\"linknews\"]=linknews\n",
    "\n",
    "    # 2- JPL Mars Space Images - Featured Image\n",
    "    url_image = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(url_image)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    imagelink = soup.find('ul', class_='articles')('li',class_= \"slide\")[0]('a',class_=\"fancybox\")[0][\"data-fancybox-href\"]\n",
    "    imagefullink = \"https://www.jpl.nasa.gov\" + imagelink\n",
    "    marsdata[\"Marslatestimagelink\"] = imagefullink\n",
    "\n",
    "    # 3- Mars Weather\n",
    "    url_weather = \"https://twitter.com/marswxreport?lang=en\"\n",
    "    browser.visit(url_weather)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    #Since all tweets will be quote stored in li tags with class_=\"js-stream-item stream-item stream-item '\")\n",
    "    weathercheck = soup.find_all('li',class_='js-stream-item stream-item stream-item ')\n",
    "    check = \"\"\n",
    "    for weather in weathercheck:\n",
    "    #But just tweet from original Mars Weather using the class: tweet js-stream-tweet js-actionable-tweet js-profile-popup-actionable dismissible-content original-tweet js-original-tweet \n",
    "        if (weather('div',class_=\"tweet js-stream-tweet js-actionable-tweet js-profile-popup-actionable dismissible-content original-tweet js-original-tweet \")):\n",
    "            check = weather('div',class_=\"tweet js-stream-tweet js-actionable-tweet js-profile-popup-actionable dismissible-content original-tweet js-original-tweet \")\n",
    "            #This condition is redundant but to make sure tweet is from MARS WEATHER and for weather data by every single tweet frm Mars Weather will be displayed \"MarsWxReport\"\n",
    "            if (check[0][\"data-screen-name\"] == \"MarsWxReport\"):\n",
    "                #After find the first one with above conditions then assign as lastest tweet\n",
    "                break\n",
    "    #Slice weather data of that lastest tweet \n",
    "    mars_weather = check[0]('div',class_=\"js-tweet-text-container\")[0]('p',class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")[0].text\n",
    "    marsdata[\"weatherinfo\"] = mars_weather\n",
    "\n",
    "    # 4- Mars Facts\n",
    "    urlmarsfacts = 'https://space-facts.com/mars/'\n",
    "    table = pd.read_html(urlmarsfacts)\n",
    "    dfmars=table[0]\n",
    "    dfmars.columns=['Description','Value']\n",
    "    dfmars.set_index('Description',inplace= True)\n",
    "    html_tablemarsfacts = dfmars.to_html()\n",
    "    html_tablemarsfacts = html_tablemarsfacts.replace('\\n', '')\n",
    "    marsdata[\"marsfact\"] = html_tablemarsfacts\n",
    "\n",
    "    # 5- Mars Hemispheres\n",
    "    urlHemispheres = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(urlHemispheres)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #Find the links\n",
    "    links = soup.find_all('div',class_=\"item\")\n",
    "    link = []\n",
    "    for lnk in links:\n",
    "        link.append(\"https://astrogeology.usgs.gov\" + lnk('a',class_=\"itemLink product-item\")[0][\"href\"])\n",
    "    \n",
    "    hemisphere_image_urls=[]\n",
    "    for detail in link:\n",
    "        title = \"\"\n",
    "        img_url=\"\"\n",
    "        listitem={\"title\":\"\",\"img_url\":\"\"}\n",
    "        browser.visit(detail)\n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        title = soup('h2',class_=\"title\")[0].text\n",
    "        img_url= soup('div',class_=\"wide-image-wrapper\")[0]('a')[0][\"href\"]\n",
    "        listitem[\"title\"] = title\n",
    "        listitem[\"img_url\"]=img_url\n",
    "        hemisphere_image_urls.append(listitem)\n",
    "    marsdata[\"link\"] = link\n",
    "    marsdata[\"marshemisphereimage\"] = hemisphere_image_urls\n",
    "\n",
    "    return marsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
